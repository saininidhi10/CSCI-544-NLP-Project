{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_NER_Tagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce4O9XE3uVlq"
      },
      "source": [
        "## Importing all the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLAG1WzUHMLs"
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "!pip install bert\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import nltk\n",
        "import pdb\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "import torch.optim as optim\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqvk_brNGQ13",
        "outputId": "12254d12-f6b8-462e-df5b-ee9faa8cdb53"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPocavSkH9pI"
      },
      "source": [
        "\"\"\"\n",
        "Checking if the machine has the \"GPU\" unit for the computation otherwise selecting the \"CPU\"\n",
        "\"\"\"\n",
        "\n",
        "def get_device():\n",
        "\tdevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\treturn device\n",
        "\n",
        "\"\"\"\n",
        "Getting BERT Tokenizer from the \"bert-based-cased\" mode. \n",
        "This model is pretrained on thousands of Books and Wikipedia Articles.\n",
        "\"\"\"\n",
        "def get_tokenizer():\n",
        "\ttokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
        "\treturn tokenizer\n",
        "\n",
        "class PosDataset(data.Dataset):\n",
        "    def __init__(self, tagged_sents,tokenizer,tag2idx,idx2tag):\n",
        "        sents, tags_li = [], [] # list of lists\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tag2idx = tag2idx\n",
        "        self.idx2tag = idx2tag\n",
        "        for sent in tagged_sents:\n",
        "            words = [word_pos[0] for word_pos in sent]\n",
        "            tags = [word_pos[1] for word_pos in sent]\n",
        "            sents.append([\"[CLS]\"] + words + [\"[SEP]\"])\n",
        "            tags_li.append([\"<pad>\"] + tags + [\"<pad>\"])\n",
        "        self.sents, self.tags_li = sents, tags_li\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sents)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        words, tags = self.sents[idx], self.tags_li[idx] # words, tags: string list\n",
        "\n",
        "        # We give credits only to the first piece.\n",
        "        x, y = [], [] # list of ids\n",
        "        is_heads = [] # list. 1: the token is the first piece of a word\n",
        "        for w, t in zip(words, tags):\n",
        "            tokens = self.tokenizer.tokenize(w) if w not in (\"[CLS]\", \"[SEP]\") else [w]\n",
        "            xx = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "            is_head = [1] + [0]*(len(tokens) - 1)\n",
        "\n",
        "            t = [t] + [\"<pad>\"] * (len(tokens) - 1)  # <PAD>: no decision\n",
        "            yy = [self.tag2idx[each] for each in t]  # (T,)\n",
        "\n",
        "            x.extend(xx)\n",
        "            is_heads.extend(is_head)\n",
        "            y.extend(yy)\n",
        "\n",
        "        assert len(x)==len(y)==len(is_heads), \"len(x)={}, len(y)={}, len(is_heads)={}\".format(len(x), len(y), len(is_heads))\n",
        "\n",
        "        # seqlen\n",
        "        seqlen = len(y)\n",
        "\n",
        "        # to string\n",
        "        words = \" \".join(words)\n",
        "        tags = \" \".join(tags)\n",
        "        return words, x, is_heads, tags, y, seqlen\n",
        "\n",
        "\"\"\"\n",
        "This function is responsible for providing propoer padding to the sentences according to the batch size.\n",
        "\"\"\"\n",
        "def pad(batch):\n",
        "    '''Pads to the longest sample'''\n",
        "    f = lambda x: [sample[x] for sample in batch]\n",
        "    words = f(0)\n",
        "    is_heads = f(2)\n",
        "    tags = f(3)\n",
        "    seqlens = f(-1)\n",
        "    maxlen = np.array(seqlens).max()\n",
        "\n",
        "    f = lambda x, seqlen: [sample[x] + [0] * (seqlen - len(sample[x])) for sample in batch] # 0: <pad>\n",
        "    x = f(1, maxlen)\n",
        "    y = f(-2, maxlen)\n",
        "    f = torch.LongTensor\n",
        "    return words, f(x), is_heads, tags, f(y), seqlens\n",
        "\"\"\"\n",
        "BERT Layer Architecture\n",
        "This class is Deep Neural Network class in which we are using BERT implementation and \n",
        "adding a Linear layer which is converting the BERT 768 vector output to the size of the tags.\n",
        "\"\"\"\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, vocab_size=None,device = None):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "        self.fc = nn.Linear(768, vocab_size)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        \n",
        "        if self.training:\n",
        "            self.bert.train()\n",
        "            encoded_layers, _ = self.bert(x)\n",
        "            enc = encoded_layers[-1]\n",
        "        else:\n",
        "            self.bert.eval()\n",
        "            with torch.no_grad():\n",
        "                encoded_layers, _ = self.bert(x)\n",
        "                enc = encoded_layers[-1]\n",
        "        \n",
        "        logits = self.fc(enc)\n",
        "        y_hat = logits.argmax(-1)\n",
        "        return logits, y, y_hat\n",
        "\"\"\"\n",
        "This function is responsible for the training the extra 1 layer on the top of the pretrained BERT model\n",
        "to fine-tune the BERT model on our dataset.\n",
        "For each epoch, we are using batching to optimize the trainign speed.\n",
        "\"\"\"\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    for j in range(20):\n",
        "      for i, batch in enumerate(iterator):\n",
        "          words, x, is_heads, tags, y, seqlens = batch\n",
        "          _y = y # for monitoring\n",
        "          optimizer.zero_grad()\n",
        "          logits, y, _ = model(x, y) # logits: (N, T, VOCAB), y: (N, T)\n",
        "\n",
        "          logits = logits.view(-1, logits.shape[-1]) # (N*T, VOCAB)\n",
        "          y = y.view(-1)  # (N*T,)\n",
        "\n",
        "          loss = criterion(logits, y)\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          if i%10==0: # monitoring\n",
        "              print(\"step: {}, loss: {}\".format(i, loss.item()))\n",
        "\"\"\"\n",
        "This function is responsible for evaluating the test results and saving the \n",
        "predictions in results file which can be further used for calculating the \n",
        "precision, recall and F1-Score.\n",
        "At the end, this function also calculated the accuracy on the test dataset from \n",
        "the true and predicted labels.\n",
        "\"\"\"\n",
        "def eval(model, iterator,tag2idx,idx2tag):\n",
        "    model.eval()\n",
        "\n",
        "    Words, Is_heads, Tags, Y, Y_hat = [], [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            words, x, is_heads, tags, y, seqlens = batch\n",
        "\n",
        "            _, _, y_hat = model(x, y)  # y_hat: (N, T)\n",
        "\n",
        "            Words.extend(words)\n",
        "            Is_heads.extend(is_heads)\n",
        "            Tags.extend(tags)\n",
        "            Y.extend(y.numpy().tolist())\n",
        "            Y_hat.extend(y_hat.cpu().numpy().tolist())\n",
        "\n",
        "    ## gets results and save\n",
        "    with open(\"result\", 'w') as fout:\n",
        "        for words, is_heads, tags, y_hat in zip(Words, Is_heads, Tags, Y_hat):\n",
        "            y_hat = [hat for head, hat in zip(is_heads, y_hat) if head == 1]\n",
        "            preds = [idx2tag[hat] for hat in y_hat]\n",
        "            assert len(preds)==len(words.split())==len(tags.split())\n",
        "            for w, t, p in zip(words.split()[1:-1], tags.split()[1:-1], preds[1:-1]):\n",
        "                fout.write(\"{} {} {}\\n\".format(w, t, p))\n",
        "            fout.write(\"\\n\")\n",
        "            \n",
        "    ## calc metric\n",
        "    y_true =  np.array([tag2idx[line.split()[1]] for line in open('result', 'r').read().splitlines() if len(line) > 0])\n",
        "    y_pred =  np.array([tag2idx[line.split()[2]] for line in open('result', 'r').read().splitlines() if len(line) > 0])\n",
        "\n",
        "    acc = (y_true==y_pred).astype(np.int32).sum() / len(y_true)\n",
        "\n",
        "    print(\"acc=%.2f\"%acc)\n",
        "\"\"\"\n",
        "This function is responsible for getting the predictions on the test dataset. \n",
        "For each of the test dataset Evaluation is called to get the predictions from the model.\n",
        "\"\"\"\n",
        "def test(model, iterator,tag2idx,idx2tag):\n",
        "\tmodel.eval()\n",
        "\tWords, Is_heads, Tags, Y, Y_hat = [], [], [], [], []\n",
        "\twith torch.no_grad():\n",
        "\t\tfor i, batch in enumerate(iterator):\n",
        "\t\t\twords, x, is_heads, tags, y, seqlens = batch\n",
        "\n",
        "\t\t_, _, y_hat = model(torch.tensor(x), torch.tensor(y))  # y_hat: (N, T)\n",
        "\n",
        "\t\tWords.extend(words)\n",
        "\t\tIs_heads.extend(is_heads)\n",
        "\t\tTags.extend(tags)\n",
        "\t\tY.extend(y.numpy().tolist())\n",
        "\t\tY_hat.extend(y_hat.cpu().numpy().tolist())\n",
        "\n",
        "\t## get results\n",
        "\tfor words, is_heads, tags, y_hat in zip(Words, Is_heads, Tags, Y_hat):\n",
        "\t\ty_hat = [hat for head, hat in zip(is_heads, y_hat) if head == 1]\n",
        "\t\tpreds = [idx2tag[hat] for hat in y_hat]\n",
        "\t\tassert len(preds)==len(words.split())==len(tags.split())\n",
        "\t\tret_arr = []\n",
        "\t\tfor w, t, p in zip(words.split()[1:-1], tags.split()[1:-1], preds[1:-1]):\n",
        "\t\t\t#print(\"{} {}\".format(w, p))\n",
        "\t\t\tret_arr.append(tuple((w,p)))\n",
        "\treturn ret_arr\n",
        "\t\t\n",
        "def construct_input(sent):\n",
        "    words = [word_pos for word_pos in sent.split()]\n",
        "    tags = ['-NONE-' for word_pos in sent.split()]\n",
        "    #print(tags)\n",
        "    ret_arr = []\n",
        "    for i,j in zip(words,tags):\n",
        "      ret_arr.append(tuple((i,j)))\n",
        "    return [ret_arr]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je6FpkfSL_wo"
      },
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"conll2003\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs6SG8xVMY94"
      },
      "source": [
        "\"\"\"\n",
        "This function is responsible for creating the tupes of word and its corresponding NER tag and returns the list of list.\n",
        "For each sentence, it will return the list of tuples having each word and its corresponding actual NER Tag.\n",
        "\"\"\"\n",
        "def get_tuples_data(dataframe):\n",
        "  bert_pos_input = []\n",
        "  bert_ner_input = []\n",
        "  for name, each_df in dataframe.groupby(by=[\"sentence_id\"]): \n",
        "    pos_records = each_df[[\"words\", \"ner_labels\"]].to_records(index=False)\n",
        "    bert_ner_input.append(list(pos_records))\n",
        "  return bert_pos_input, bert_ner_input"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYumE6bbfxZ9"
      },
      "source": [
        "## We are loading the `Train`, `Test` and `Dev/Validation` dataset from the Conll2003 Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sAR-sRCbBVr"
      },
      "source": [
        "## Loading The `Conll2003` Dataset for the Training, Validation and Testing the BERT Implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ8XXua-HJlQ"
      },
      "source": [
        "def split_text_label(filename):\n",
        "    f = open(filename)\n",
        "    split_labeled_text = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line)== 0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                split_labeled_text.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        sentence.append([splits[1],splits[-1].rstrip(\"\\n\")])\n",
        "    if len(sentence) > 0:\n",
        "        split_labeled_text.append(sentence)\n",
        "        sentence = []\n",
        "    res = []\n",
        "    for pos,sen in enumerate(split_labeled_text):\n",
        "      for word in sen:\n",
        "        r = [pos,word[0],word[1]]\n",
        "        res.append(r)\n",
        "    return pd.DataFrame(res,columns=['sentence_id','words','ner_labels'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8deTW3OzJN9P"
      },
      "source": [
        "df = split_text_label('/content/drive/MyDrive/conll2003/english/eng.train.bioes.conll')\n",
        "df_validation = split_text_label('/content/drive/MyDrive/conll2003/english/eng.dev.bioes.conll')\n",
        "df_test = split_text_label('/content/drive/MyDrive/conll2003/english/eng.test.bioes.conll')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxKj6raxM1Vu"
      },
      "source": [
        "bert_pos_input_train, bert_ner_input_train = get_tuples_data(df)\n",
        "bert_pos_input_validation, bert_ner_input_validation = get_tuples_data(df_validation)\n",
        "bert_pos_input_test, bert_ner_input_test = get_tuples_data(df_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNLibuaD6PT_"
      },
      "source": [
        "\"\"\"\n",
        "This function is responsbile for all the training and fine-tuning of the BERT Implementation.\n",
        "We are creating the object of BERT Model and then creating objects for Optimizer and \n",
        "Criterion to fine-tune the pretrained weights.\n",
        "\"\"\"\n",
        "def train_model(model_dir):\n",
        "\n",
        "\ttagged_sents= bert_ner_input_train\n",
        "\ttags = list(set(word_pos[1] for sent in tagged_sents for word_pos in sent))\n",
        "\ttags = [\"<pad>\"] + tags\n",
        "\ttags_str = ','.join(tags)\n",
        "\ttag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
        "\tidx2tag = {idx:tag for idx, tag in enumerate(tags)}\n",
        "\ttag2idx[\"-NONE-\"]=len(tag2idx)\n",
        "\tprint(\"our tags are:\",tags)\n",
        "\tprint(\"our tag2idx is:\",tag2idx)\n",
        "\tfrom sklearn.model_selection import train_test_split\n",
        "\ttrain_data = bert_ner_input_train\n",
        "\ttest_data = bert_ner_input_validation\n",
        "\n",
        "\tdevice = get_device() \n",
        "\ttokenizer = get_tokenizer()\n",
        "\tprint(device)\n",
        "\n",
        "\tmodel = Net(vocab_size=len(tag2idx),device = device)\n",
        "\tmodel.to(device)\n",
        "\tmodel = nn.DataParallel(model)\n",
        "\n",
        "\ttrain_dataset = PosDataset(train_data,tokenizer,tag2idx,idx2tag)\n",
        "\teval_dataset = PosDataset(test_data,tokenizer,tag2idx,idx2tag)\n",
        "\n",
        "\ttrain_iter = data.DataLoader(dataset=train_dataset,\n",
        "                             batch_size=16,\n",
        "                             shuffle=True,\n",
        "                             num_workers=1,\n",
        "                             collate_fn=pad)\n",
        "\ttest_iter = data.DataLoader(dataset=eval_dataset,\n",
        "                             batch_size=32,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1,\n",
        "                             collate_fn=pad)\n",
        "\n",
        "\toptimizer = optim.Adam(model.parameters(), lr = 0.00001)\n",
        "\n",
        "\tcriterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\ttrain(model, train_iter, optimizer, criterion)\n",
        "\teval(model, test_iter,tag2idx,idx2tag)\n",
        "\n",
        "\tprint(\"Saving model...\")\n",
        "\ttorch.save(model, model_dir + \"/pytorch_model.bin\")\n",
        "\tprint(\"Model saved\")\n",
        "\ttags_arr = [tag2idx,idx2tag]\n",
        "\tprint(\"Pickling tags...\")\n",
        "\tfp = open(model_dir +\"/tags.pkl\",\"wb\")\n",
        "\tpickle.dump(tags_arr,fp)\n",
        "\tfp.close()\n",
        "\tprint(\"Pickling complete...\")\n",
        "\t#print(open('result', 'r').read().splitlines()[:100])\n",
        "\n",
        "if __name__== \"__main__\":\n",
        "\tif (len(sys.argv) < 2):\n",
        "\t\tprint(\"Specify model dir to save\")\n",
        "\telse:\n",
        "\t\ttry:\n",
        "\t\t\tos.mkdir(sys.argv[1])\n",
        "\t\texcept:\n",
        "\t\t\tprint(\"Directory already exists\")\n",
        "\t\ttrain_model(sys.argv[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4JuV1kHOZ6-"
      },
      "source": [
        "def get_test_sentenses(dataframe):\n",
        "  test_sentences = []\n",
        "  i=0\n",
        "  while i <len(dataframe):\n",
        "    curr_id = dataframe.iloc[i]['sentence_id']\n",
        "    j = i\n",
        "    curr_sentence = []\n",
        "    while j < len(dataframe) and curr_id == dataframe.iloc[j]['sentence_id']:\n",
        "      curr_sentence.append(dataframe.iloc[j]['words'])\n",
        "      j+=1\n",
        "    test_sentences.append(' '.join(curr_sentence))\n",
        "    i = j\n",
        "  return test_sentences, list(dataframe['ner_labels'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUQiWAK1G2ux"
      },
      "source": [
        "def calculate_accracy(predicted_tags,actual_tag):\n",
        "  tags=[]\n",
        "  for sublist in predicted_tags:\n",
        "    for item in sublist:\n",
        "      tags.append(item[1])\n",
        "  acc = accuracy_score(actual_tag, tags)  \n",
        "  print(acc)\n",
        "  print('macro',f1_score(actual_tag, tags, average='macro'))\n",
        "  print('micro',f1_score(actual_tag, tags, average='micro'))\n",
        "  print('weighted',f1_score(actual_tag, tags, average='weighted'))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ykfwwhM6WUs"
      },
      "source": [
        "def test_model(test_data,actual_test_data):\n",
        "    model_dir = sys.argv[1]\n",
        "    predicted_tags = []\n",
        "    device = get_device() \n",
        "    tokenizer = get_tokenizer()\n",
        "    \n",
        "    print(\"Loading model ...\")\n",
        "    model= torch.load(\"/content/-f/pytorch_model.bin\")\n",
        "    print(\"Loading model complete\")\n",
        "    print(\"Loading Pickling tags...\")\n",
        "    fp = open(\"/content/-f/tags.pkl\",\"rb\")\n",
        "    tags_arr = pickle.load(fp)\n",
        "    print(\"Loading Pickling tags complete\")\n",
        "    fp.close()\n",
        "    \n",
        "    for text in test_data:\n",
        "      rt_test_dataset = PosDataset(construct_input(text),tokenizer,tags_arr[0],tags_arr[1])\n",
        "      rt_test_iter = data.DataLoader(dataset=rt_test_dataset,\n",
        "                              batch_size=32,\n",
        "                              shuffle=False,\n",
        "                              num_workers=1,\n",
        "                              collate_fn=pad)\n",
        "\n",
        "      ret_arr = test(model, rt_test_iter,tags_arr[0],tags_arr[1])\n",
        "      predicted_tags.append(ret_arr)\n",
        "    return predicted_tags,actual_test_data\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD1DFH_fjBn2"
      },
      "source": [
        "### Calculating the Accuracy on the Test Dataset using the SkLearn Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaXOYDKwQJn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a8399c-9f16-40f4-b751-9bcdf6eec8d8"
      },
      "source": [
        "test_sentances,test_sentances_tag = get_test_sentenses(df_test)\n",
        "pt,at = test_model(test_sentances,test_sentances_tag)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model ...\n",
            "Loading model complete\n",
            "Loading Pickling tags...\n",
            "Loading Pickling tags complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7l56E3e3hnP"
      },
      "source": [
        "def create_out_file(data_set,predicted_tags,actual_tag,file_name):\n",
        "  p_tags=[]\n",
        "  flat_list = []\n",
        "  for s in predicted_tags:\n",
        "    for sublist in s:\n",
        "      flat_list.append(sublist)\n",
        "  for res in flat_list:\n",
        "    p_tags.append(res)\n",
        "  data_set_new = np.array(data_set)\n",
        "  file_object = open(file_name+'.out', 'a')\n",
        "  for pos,each in enumerate(data_set_new):\n",
        "    s = str(each[0])+' '+each[1]+' '+each[2]+' '+(p_tags[pos][1])+'\\n'\n",
        "    file_object.write(s)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cisHw5234duo"
      },
      "source": [
        "create_out_file(df_test,pt,test_sentances_tag,'test_out')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDHBpc51_X8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba982c4d-df7f-40de-eadb-3efef23f5b37"
      },
      "source": [
        "!perl /content/conlleval.v2 < /content/test_out.out"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 46666 tokens with 5648 phrases; found: 5778 phrases; correct: 5172.\n",
            "accuracy:  98.02%; precision:  89.51%; recall:  91.57%; FB1:  90.53\n",
            "              LOC: precision:  92.75%; recall:  92.75%; FB1:  92.75  1668\n",
            "             MISC: precision:  82.63%; recall:  81.34%; FB1:  81.98  691\n",
            "              ORG: precision:  83.38%; recall:  92.11%; FB1:  87.53  1835\n",
            "              PER: precision:  96.21%; recall:  94.25%; FB1:  95.22  1584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIyfD2tmj4kS"
      },
      "source": [
        "## Evaluating the Test Results using the Perl Script to calculate the Accuracy, Precision, Recall and F-1 Score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8e0-LhDLmDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3dd130-ac92-4c93-e6cb-e32499f5c458"
      },
      "source": [
        "dev_sentances,dev_sentances_tag = get_test_sentenses(df_validation)\n",
        "p,a = test_model(dev_sentances,dev_sentances_tag)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model ...\n",
            "Loading model complete\n",
            "Loading Pickling tags...\n",
            "Loading Pickling tags complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbi9p_BSiv9_"
      },
      "source": [
        "create_out_file(df_validation,p,a,'dev_out')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3epchIVi1AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f62fd52-31f9-42d5-e23b-07c5aea58ddd"
      },
      "source": [
        "!perl /content/conlleval.v2 < /content/dev_out.out"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed 51578 tokens with 5942 phrases; found: 6003 phrases; correct: 5636.\n",
            "accuracy:  98.94%; precision:  93.89%; recall:  94.85%; FB1:  94.37\n",
            "              LOC: precision:  96.79%; recall:  95.26%; FB1:  96.02  1808\n",
            "             MISC: precision:  90.65%; recall:  89.37%; FB1:  90.01  909\n",
            "              ORG: precision:  87.42%; recall:  94.85%; FB1:  90.99  1455\n",
            "              PER: precision:  97.76%; recall:  97.18%; FB1:  97.47  1831\n"
          ]
        }
      ]
    }
  ]
}